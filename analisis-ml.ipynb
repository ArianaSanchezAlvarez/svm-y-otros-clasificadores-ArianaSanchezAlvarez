{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/ml-unison/regresion-logistica/master/imagenes/ml-unison.png\" width=\"250\">\n",
    "\n",
    "# Diferentes técnicas de aprendizaje máquina\n",
    "\n",
    "**Julio Waissman Vianova**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Conjuntos de datos de prueba en sklearn que utlizaremos\n",
    "#----------------------------------------------------------\n",
    "\n",
    "# Los conjuntos artificiales típicos para probar datos\n",
    "from sklearn.datasets import make_moons           # En forma de medialunas \n",
    "from sklearn.datasets import make_circles         # En forma de círculos\n",
    "from sklearn.datasets import make_classification  # Como separación lineal\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Los métodos de aprendizaje a utilizar ya provenientes de sklearn\n",
    "#------------------------------------------------------------------\n",
    "from sklearn.neighbors import KNeighborsClassifier      # KNN\n",
    "from sklearn.svm import SVC                             # SVM\n",
    "from sklearn.tree import DecisionTreeClassifier         # Arbol decisión\n",
    "from sklearn.ensemble import RandomForestClassifier     # Bósque aleatorios\n",
    "from sklearn.ensemble import AdaBoostClassifier         # ADA Boost\n",
    "from sklearn.naive_bayes import GaussianNB              # Naive bayes\n",
    "from sklearn.linear_model import  LogisticRegression    # Logística con regularización\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis   # Logística con polinomio de orden 2 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Comparasión de diferentes clasificadores\n",
    "\n",
    "Muestra para 3 conjuntos de datos artificiales bidimensionales, la forma en que se realiza la clasificación con distintos métodos. Principalmente lo hacemos para poder sacar conclusiones sobre en que situaciones un método puede ser mejor que otros, y que está haciendo internamente.\n",
    "\n",
    "Codigo obtenido de la documentación de scikit-learn, el cual se puede consultar [aquí](http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Generando 3 conjuntos de aprendizaje sintéticos\n",
    "ara probar como funcionan los diferentes tipos de clasificadores, primero vamos a revisar cual es el tipo de partición del espacio que se espera con cada uno de ellos en 3 casos diferentes. Para los tres casos se va a generar 3 conjuntos de datos sintéticos es dos dimensiones (con el fin de graficar las diferencias).\n",
    "\n",
    "Estos tres conjuntos son de la siguiente forma:\n",
    "\n",
    "1. El primer conjunto tiene forma de media luna los datos de una clase respecto a la otra.\n",
    "\n",
    "2. En el segundo conjunto de datos, los datos de las dos clases están en círculos concéntricos.\n",
    "\n",
    "3. El tercer caso son datos linealmente separables con ruido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Datos en forma de media luna\n",
    "X1, y1 = make_moons(noise=0.3, random_state=0)\n",
    "\n",
    "# Datos en forma de círculos\n",
    "X2, y2 = make_circles(noise=0.2, factor=0.5, random_state=1)\n",
    "\n",
    "# Datos en forma de regresion lineal\n",
    "X3, y3 = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                             random_state=1, n_clusters_per_class=1)\n",
    "# Le agregamos ruido para hacerlos interesantes\n",
    "rng = np.random.RandomState(2)\n",
    "X3 += 2 * rng.uniform(size=X3.shape)\n",
    "\n",
    "# Los conjuntos de datos irdenados como una lista de pares ordenados\n",
    "datasets = [(X1, y1), (X2, y2), (X3, y3)]\n",
    "\n",
    "# Y los grafiacamos para verlos\n",
    "figure = plt.figure(figsize=(30, 10))\n",
    "cm_escala = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "for (i, ds) in enumerate(datasets):\n",
    "\n",
    "    # Selecciona los valores del conjunto de datos y los escala\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # Grafica\n",
    "    ax = plt.subplot(1, 3, i+1)\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, s=150, cmap=cm_escala)\n",
    "    ax.set_xlim(X[:, 0].min() - .5, X[:, 0].max() + .5)\n",
    "    ax.set_ylim(X[:, 1].min() - .5, X[:, 1].max() + .5)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "figure.subplots_adjust(left=.02, right=.98)    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.2. Definiendo una la bateria de clasificadores diferentes\n",
    "\n",
    "En esta sección se va a generar una batería de diferentes objetos clasificador, cada uno proveniente de una técnica diferente. Todos los vamos a guardar en una lista de objetos tipo clasificador de `sklearn`.\n",
    "\n",
    "Una ventaja de `sklearn` es que todos los objetos clasificador se pueden ajustar sus parámetros en la inicialización, y todos (sean del tipo que sean) utilizan varios métodos, siempre de la misma manera, en particular: `clf.fit` para el aprendizaje y `cls.predict`para el reconocimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "clasificadores = [\n",
    "    KNeighborsClassifier(3),                  # 3 vecinos próximos\n",
    "    SVC(kernel=\"linear\", C=0.025),            # SVC lineal con C = 0.025\n",
    "    SVC(gamma=2, C=1),                        # SVC gaussiano con gamma = 2 y C = 1\n",
    "    DecisionTreeClassifier(max_depth=5),      # Árbol de decisión con máxima profundidad de 5\n",
    "    RandomForestClassifier(max_depth=5,       # Bósque aleatorios con 10 árboles \n",
    "                           n_estimators=10, \n",
    "                           max_features=1),\n",
    "    AdaBoostClassifier(),                     # ADA Boost \n",
    "    GaussianNB(),                             # Naive bayes con distribución gaussiana\n",
    "    LogisticRegression(solver='lbfgs'),       # Logística \n",
    "    QuadraticDiscriminantAnalysis()           # Logística con términos cuadráticos \n",
    "]\n",
    "\n",
    "# Solo para fines de graficación\n",
    "titulos = [\"3 vecinos próximos\", \n",
    "           \"SVM lineal\", \n",
    "           \"SVM gaussiano\", \n",
    "           \"Árbol de desición\",\n",
    "           \"Boseques aleatórios\", \n",
    "           \"AdaBoost\", \n",
    "           \"Naive Bayes\", \n",
    "           \"Logística\",\n",
    "           \"Discriminante cuadrático\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.3. Generando la clasificación con cada método diferente\n",
    "\n",
    "Por cada método establecido, y por cada conjunto de datos, vamos a realizar la clasificación con los datos de aprendizaje, y luego vamos a realizar la predicción con un monton de puntos del espacio (en forma de rejilla) con tal de poner de manifiesto cual es el tipo de partición que induce cada uno de los algoritmos propuestos.\n",
    "\n",
    "Esto se realiza en forma genética, así que es exactamente igual para todos los mñetodos. Por esto se utilizan varios comandos provenientes de `matplotlib`para generar los datos para reconocer en forma de rejilla, y se realizan algunas operaciones no tan comunes para graficar, que se espera no haya problema en entenderlas, al ser solo un problema técnico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## Vamos a escoger una escala de colores de alto contraste\n",
    "cm = plt.cm.RdBu\n",
    "cm_escala = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "for (cual, ds) in enumerate(datasets):\n",
    "    \n",
    "    print('\\n' * 3)\n",
    "    print(\"*\"*30 + \"\\n\")\n",
    "    print(\"Base de datos \" + str(cual + 1))\n",
    "    print(\"*\"*30 + \"\\n\")\n",
    "    figure = plt.figure(figsize=(30, 30))\n",
    "\n",
    "\n",
    "    # Escalar y selecciona valores de entrenamiento y prueba\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4)\n",
    "\n",
    "    # Meshgrid para pintar las regiones\n",
    "    xx, yy = np.meshgrid(np.arange(X[:, 0].min() - .5, X[:, 0].max() + .5, 0.02),\n",
    "                         np.arange(X[:, 1].min() - .5, X[:, 1].max() + .5, 0.02))\n",
    "\n",
    "    # Por cada clasificador\n",
    "    for (i, (titulo, clf)) in enumerate(zip(titulos, clasificadores)):\n",
    "        \n",
    "        # Escoge el subplot\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        \n",
    "        # El entrenamiento!!!!\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Encuentra el error de validación\n",
    "        score = clf.score(X_test, y_test)\n",
    "\n",
    "        # Clasifica cada punto en el meshgrid\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "        # Asigna un color a cada punto\n",
    "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "        # Grafica los datos de entrenamiento y prueba\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_escala, s=150)\n",
    "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_escala, s=150, alpha=0.6)\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        ax.set_title(titulo, size=30)\n",
    "        ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "                size=30, horizontalalignment='right')\n",
    "\n",
    "    figure.subplots_adjust(left=.02, right=.98)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Ejercicio 1.\n",
    "\n",
    "Para cada una de las técnicas, describe en que casos crees que la técnica sería de las mejores técnics a utilizar como método de clasificación (puedes consultar bibbliografía o solo apoyarte en los resultados, pero tiene que ser congruente).\n",
    "\n",
    "1. **3 vecinos próximos**: Agrega tu comentario aquí.\n",
    "\n",
    "2. **SVM lineal**: Agrega tu comentario aquí.\n",
    "\n",
    "3. **SVM gaussiano**: Agrega tu comentario aquí.\n",
    "\n",
    "4. **Árbol de desición**: Agrega tu comentario aquí.\n",
    "\n",
    "5. **Boseques aleatórios**: Agrega tu comentario aquí.\n",
    "\n",
    "6. **AdaBoost**: Agrega tu comentario aquí.\n",
    " \n",
    "7. **Naive Bayes**: Agrega tu comentario aquí. \n",
    "\n",
    "8. **Discriminante lineal**: Agrega tu comentario aquí.\n",
    "\n",
    "9. **Discriminante cuadrático**: Agrega tu comentario aquí."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('curso-ml': conda)",
   "display_name": "Python 3.8.5 64-bit ('curso-ml': conda)",
   "metadata": {
    "interpreter": {
     "hash": "d4f800d24c24a9a4af9a7fb520b7196da0c35924aa8fd5669684582c6905ccb4"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}